{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#logistic regression\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from numpy import loadtxt, where\n",
    "from pylab import scatter, show, legend, xlabel, ylabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터에 대한 스케일 조정\n",
    "min_max_scaler = preprocessing.MinMaxScaler(feature_range = (-1,1))\n",
    "df = pd.read_csv('C:/Users/admin/Desktop/새홀리기/data.csv', header = 0, engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data clean\n",
    "df.columns = [\"grade1\", \"grade2\", \"label\"]\n",
    "x = df[\"label\"].map(lambda x : float(x.rstrip(';'))) #label의 각 value마다 하나씩 꺼내서 x : 뒤의 작업을 수행한 후 다시 넣는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#종속 변수와 독립 변수 분리\n",
    "X = df[[\"grade1\", \"grade2\"]]\n",
    "X = np.array(X) #array로 바꿔줌\n",
    "X = min_max_scaler.fit_transform(X) #스케일 조정\n",
    "Y = df[\"label\"].map(lambda x : float(x.rstrip(';')))\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data set 나누기\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size = 0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score scikit-learn :  0.9090909090909091\n"
     ]
    }
   ],
   "source": [
    "#scikit-learn으로 모델 훈련 시키기\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, Y_train)\n",
    "print(\"score scikit-learn : \", clf.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualize data\n",
    "pos = where(Y == 1)\n",
    "neg = where(Y == 0)\n",
    "scatter(X[pos,0], X[pos,1], marker ='o', c = 'b')\n",
    "scatter(X[neg,0], X[neg,1], marker = 'x', c = 'r')\n",
    "xlabel('Exam 1 score')\n",
    "ylabel('Exam 2 score')\n",
    "legend(['Not Admitted', 'Admitted'])\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "##The sigmoid function adjusts the cost function hypotheses to adjust the algorithm proportionally for worse estimations\n",
    "def Sigmoid(z):\n",
    "    G_of_Z = float(1.0 / float((1.0 + math.exp(-1.0*z))))\n",
    "    return G_of_Z \n",
    "\n",
    "##The hypothesis is the linear combination of all the known factors x[i] and their current estimated coefficients theta[i] \n",
    "##This hypothesis will be used to calculate each instance of the Cost Function\n",
    "def Hypothesis(theta, x):\n",
    "    z = 0\n",
    "    for i in range(len(theta)):\n",
    "        z += x[i]*theta[i]\n",
    "    return Sigmoid(z)\n",
    "\n",
    "##For each member of the dataset, the result (Y) determines which variation of the cost function is used\n",
    "##The Y = 0 cost function punishes high probability estimations, and the Y = 1 it punishes low scores\n",
    "##The \"punishment\" makes the change in the gradient of ThetaCurrent - Average(CostFunction(Dataset)) greater\n",
    "def Cost_Function(X,Y,theta,m):\n",
    "    sumOfErrors = 0\n",
    "    for i in range(m):\n",
    "        xi = X[i]\n",
    "        hi = Hypothesis(theta,xi)\n",
    "        if Y[i] == 1:\n",
    "            error = Y[i] * math.log(hi)\n",
    "        elif Y[i] == 0:\n",
    "            error = (1-Y[i]) * math.log(1-hi)\n",
    "        sumOfErrors += error\n",
    "    const = -1/m\n",
    "    J = const * sumOfErrors\n",
    "    print('cost is ', J)\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "##This function creates the gradient component for each Theta value \n",
    "##The gradient is the partial derivative by Theta of the current value of theta minus \n",
    "##a \"learning speed factor aplha\" times the average of all the cost functions for that theta\n",
    "##For each Theta there is a cost function calculated for each member of the dataset\n",
    "def Cost_Function_Derivative(X,Y,theta,j,m,alpha):\n",
    "    sumErrors = 0\n",
    "    for i in range(m):\n",
    "        xi = X[i]\n",
    "        xij = xi[j]\n",
    "        hi = Hypothesis(theta,X[i])\n",
    "        error = (hi - Y[i])*xij\n",
    "        sumErrors += error\n",
    "    m = len(Y)\n",
    "    constant = float(alpha)/float(m)\n",
    "    J = constant * sumErrors\n",
    "    return J\n",
    "\n",
    "##For each theta, the partial differential \n",
    "##The gradient, or vector from the current point in Theta-space (each theta value is its own dimension) to the more accurate point, \n",
    "##is the vector with each dimensional component being the partial differential for each theta value\n",
    "def Gradient_Descent(X,Y,theta,m,alpha):\n",
    "    new_theta = []\n",
    "    constant = alpha/m\n",
    "    for j in range(len(theta)):\n",
    "        CFDerivative = Cost_Function_Derivative(X,Y,theta,j,m,alpha)\n",
    "        new_theta_value = theta[j] - CFDerivative\n",
    "        new_theta.append(new_theta_value)\n",
    "    return new_theta\n",
    "\n",
    "##The high level function for the LR algorithm which, for a number of steps (num_iters) finds gradients which take \n",
    "##the Theta values (coefficients of known factors) from an estimation closer (new_theta) to their \"optimum estimation\" which is the\n",
    "##set of values best representing the system in a linear combination model\n",
    "def Logistic_Regression(X,Y,alpha,theta,num_iters):\n",
    "    m = len(Y)\n",
    "    for x in range(num_iters):\n",
    "        new_theta = Gradient_Descent(X,Y,theta,m,alpha)\n",
    "        theta = new_theta\n",
    "        if x % 100 == 0:\n",
    "            #here the cost function is used to present the final hypothesis of the model in the same form for each gradient-step iteration\n",
    "            Cost_Function(X,Y,theta,m)\n",
    "            print('theta ', theta)\t\n",
    "            print('cost is ', Cost_Function(X,Y,theta,m))\n",
    "    Declare_Winner(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost is  0.6886958174712052\n",
      "theta  [0.015808968977217012, 0.014030982200249273]\n",
      "cost is  0.6886958174712052\n",
      "cost is  0.6886958174712052\n",
      "cost is  0.45043928326843835\n",
      "theta  [1.1446039323506159, 1.030383323481578]\n",
      "cost is  0.45043928326843835\n",
      "cost is  0.45043928326843835\n",
      "cost is  0.37210396400568835\n",
      "theta  [1.7920198800927762, 1.6251057941038252]\n",
      "cost is  0.37210396400568835\n",
      "cost is  0.37210396400568835\n",
      "cost is  0.33493174290971306\n",
      "theta  [2.2378078311381255, 2.0381775708737533]\n",
      "cost is  0.33493174290971306\n",
      "cost is  0.33493174290971306\n",
      "cost is  0.3134393548415864\n",
      "theta  [2.5764517180022444, 2.35358660097723]\n",
      "cost is  0.3134393548415864\n",
      "cost is  0.3134393548415864\n",
      "cost is  0.2995143683386589\n",
      "theta  [2.8487364478320787, 2.608155678935002]\n",
      "cost is  0.2995143683386589\n",
      "cost is  0.2995143683386589\n",
      "cost is  0.2898100759552151\n",
      "theta  [3.0758031030008572, 2.8210921909376734]\n",
      "cost is  0.2898100759552151\n",
      "cost is  0.2898100759552151\n",
      "cost is  0.2826976528686292\n",
      "theta  [3.2700162725064694, 3.0036648752998807]\n",
      "cost is  0.2826976528686292\n",
      "cost is  0.2826976528686292\n",
      "cost is  0.2772893938976962\n",
      "theta  [3.4392392975568247, 3.163057635787686]\n",
      "cost is  0.2772893938976962\n",
      "cost is  0.2772893938976962\n",
      "cost is  0.2730601259267772\n",
      "theta  [3.588788716304762, 3.3041402117668226]\n",
      "cost is  0.2730601259267772\n",
      "cost is  0.2730601259267772\n",
      "Scikit won.. :(\n",
      "Your score:  0.8787878787878788\n",
      "Scikits score:  0.9090909090909091\n"
     ]
    }
   ],
   "source": [
    "##This method compares the accuracy of the model generated by the scikit library with the model generated by this implementation\n",
    "def Declare_Winner(theta):\n",
    "    score = 0\n",
    "    winner = \"\"\n",
    "    #first scikit LR is tested for each independent var in the dataset and its prediction is compared against the dependent var\n",
    "    #if the prediction is the same as the dataset measured value it counts as a point for thie scikit version of LR\n",
    "    scikit_score = clf.score(X_test,Y_test)\n",
    "    length = len(X_test)\n",
    "    for i in range(length):\n",
    "        prediction = round(Hypothesis(X_test[i],theta))\n",
    "        answer = Y_test[i]\n",
    "        if prediction == answer:\n",
    "            score += 1\n",
    "    #the same process is repeated for the implementation from this module and the scores compared to find the higher match-rate\n",
    "    my_score = float(score) / float(length)\n",
    "    if my_score > scikit_score:\n",
    "        print('You won!')\n",
    "    elif my_score == scikit_score:\n",
    "        print('Its a tie!')\n",
    "    else:\n",
    "        print('Scikit won.. :(')\n",
    "    print('Your score: ', my_score)\n",
    "    print('Scikits score: ', scikit_score )\n",
    "\n",
    "# These are the initial guesses for theta as well as the learning rate of the algorithm\n",
    "# A learning rate too low will not close in on the most accurate values within a reasonable number of iterations\n",
    "# An alpha too high might overshoot the accurate values or cause irratic guesses\n",
    "# Each iteration increases model accuracy but with diminishing returns, \n",
    "# and takes a signficicant coefficient times O(n)*|Theta|, n = dataset length\n",
    "initial_theta = [0,0]\n",
    "alpha = 0.1\n",
    "iterations = 1000\n",
    "Logistic_Regression(X,Y,alpha,initial_theta,iterations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic을 이용한 nlp application(스팸 분류기)\n",
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping line 283: '\t' expected after '\"'\n",
      "Skipping line 617: '\t' expected after '\"'\n",
      "Skipping line 801: '\t' expected after '\"'\n",
      "Skipping line 1421: '\t' expected after '\"'\n",
      "Skipping line 4095: '\t' expected after '\"'\n",
      "Skipping line 4133: '\t' expected after '\"'\n",
      "Skipping line 4227: '\t' expected after '\"'\n",
      "Skipping line 4554: '\t' expected after '\"'\n",
      "Skipping line 4862: '\t' expected after '\"'\n",
      "Skipping line 5082: '\t' expected after '\"'\n"
     ]
    }
   ],
   "source": [
    "#데이터 불러오기\n",
    "path = \"C:/users/admin/Desktop/새홀리기/sms.tsv\"\n",
    "sms = pd.read_table(path, header = None, engine='python', names = ['label', 'message'], error_bad_lines=False)\n",
    "#ParserError: '\t' expected after '\"'의 해결법 : 파일에 문제가 있는것이니 error_bad_lines사용하여 그 줄을 제외한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5562, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#데이터 둘러보기\n",
    "sms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
       "5  spam  FreeMsg Hey there darling it's been 3 week's n...\n",
       "6   ham  Even my brother is not like to speak with me. ...\n",
       "7   ham  As per your request 'Melle Melle (Oru Minnamin...\n",
       "8  spam  WINNER!! As a valued network customer you have...\n",
       "9  spam  Had your mobile 11 months or more? U R entitle..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4815\n",
       "spam     747\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.label.value_counts() #label의 분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#분류를 위해 label을 숫자로 바꾼다,\n",
    "sms['label_num'] = sms.label.map({'ham' : 0, 'spam' : 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  label_num\n",
       "0   ham  Go until jurong point, crazy.. Available only ...          0\n",
       "1   ham                      Ok lar... Joking wif u oni...          0\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...          1\n",
       "3   ham  U dun say so early hor... U c already then say...          0\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...          0\n",
       "5  spam  FreeMsg Hey there darling it's been 3 week's n...          1\n",
       "6   ham  Even my brother is not like to speak with me. ...          0\n",
       "7   ham  As per your request 'Melle Melle (Oru Minnamin...          0\n",
       "8  spam  WINNER!! As a valued network customer you have...          1\n",
       "9  spam  Had your mobile 11 months or more? U R entitle...          1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x,y지정\n",
    "X = sms.message\n",
    "Y = sms.label_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4171,)\n",
      "(1391,)\n",
      "(4171,)\n",
      "(1391,)\n"
     ]
    }
   ],
   "source": [
    "#데이터 분리\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y, random_state = 1)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1391x7457 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 17143 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#문서를 벡터화 한다.\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "X_train_dtm\n",
    "X_test_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 236 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.LogisticRegression(C = 1e5)\n",
    "%time clf.fit(X_train_dtm, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test에 대한 Y_prediction\n",
    "Y_pred_class = clf.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9834651329978433"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.accuracy_score(Y_test, Y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1193,    4],\n",
       "       [  19,  175]], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(Y_test, Y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2336    Cheers for the message Zogtorius. I혪ve been st...\n",
       "3344    No problem baby. Is this is a good time to tal...\n",
       "4005    Forgot you were working today! Wanna chat, but...\n",
       "4489    Hope this text meets you smiling. If not then ...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#잘못 분류된 데이터 출력해보기\n",
    "X_test[Y_test < Y_pred_class] #false positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3456    Not heard from U4 a while. Call me now am here...\n",
       "1456    Bought one ringtone and now getting texts cost...\n",
       "2243    Hi ya babe x u 4goten bout me?' scammers getti...\n",
       "3415    LIFE has never been this much fun and great un...\n",
       "4012    You will be receiving this week's Triple Echo ...\n",
       "2911    Sorry! U can not unsubscribe yet. THE MOB offe...\n",
       "4387    RECPT 1/3. You have ordered a Ringtone. Your o...\n",
       "1773                    Call FREEPHONE 0800 542 0578 now!\n",
       "2819    ROMCAPspam Everyone around should be respondin...\n",
       "729     Email AlertFrom: Jeri StewartSize: 2KBSubject:...\n",
       "4288    Kit Strip - you have been billed 150p. Netcoll...\n",
       "3844    Fantasy Football is back on your TV. Go to Sky...\n",
       "3881    A link to your picture has been sent. You can ...\n",
       "1936    More people are dogging in your area now. Call...\n",
       "2360    Fantasy Football is back on your TV. Go to Sky...\n",
       "1634    0A$NETWORKS allow companies to bill for SMS, s...\n",
       "1042    We know someone who you know that fancies you....\n",
       "3746    Dear Voucher Holder 2 claim your 1st class air...\n",
       "4065    TBS/PERSOLVO. been chasing us since Sept for짙3...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[Y_test > Y_pred_class] #false negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.10646929e-08, 2.31314176e-09, 6.87063461e-14, ...,\n",
       "       1.00000000e+00, 2.18292384e-05, 1.25361488e-06])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_test에 대한 확률값 계산\n",
    "Y_pred_prob = clf.predict_proba(X_test_dtm)[: ,1]\n",
    "Y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9882739494785072"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#AUC\n",
    "metrics.roc_auc_score(Y_test, Y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DecisionTree를 이용한 분류\n",
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier(criterion = 'entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 468 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#훈련데이터로 모델 훈련\n",
    "%time clf.fit(X_train_dtm, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#예측값 출력\n",
    "Y_pred_class = clf.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9633357296908699"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.accuracy_score(Y_test, Y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1176,   21],\n",
       "       [  30,  164]], dtype=int64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(Y_test, Y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4741    The beauty of life is in next second.. which h...\n",
       "2336    Cheers for the message Zogtorius. I혪ve been st...\n",
       "5292    About  &lt;#&gt; bucks. The banks fees are fix...\n",
       "4063    Fyi I'm gonna call you sporadically starting a...\n",
       "1321    I thk 50 shd be ok he said plus minus 10.. Did...\n",
       "4694                               I liked the new mobile\n",
       "984     I'm in office now . I will call you  &lt;#&gt;...\n",
       "3321    I don wake since. I checked that stuff and saw...\n",
       "4758    if you text on your way to cup stop that shoul...\n",
       "2366    A Boy loved a gal. He propsd bt she didnt mind...\n",
       "5094    A Boy loved a gal. He propsd bt she didnt mind...\n",
       "329     I'm reading the text i just sent you. Its mean...\n",
       "100     Please don't text me anymore. I have nothing e...\n",
       "573                                Waiting for your call.\n",
       "5298    I'm coming back on Thursday. Yay. Is it gonna ...\n",
       "678     Missed your call cause I was yelling at scrapp...\n",
       "3144    Oh thats late! Well have a good night and i wi...\n",
       "4806            i can call in  &lt;#&gt;  min if thats ok\n",
       "494                      Are you free now?can i call now?\n",
       "5054    Havent stuck at orchard in my dad's car. Going...\n",
       "2188    Thankyou so much for the call. I appreciate yo...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[Y_test < Y_pred_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3378    complimentary 4 STAR Ibiza Holiday or 짙10,000 ...\n",
       "3456    Not heard from U4 a while. Call me now am here...\n",
       "2243    Hi ya babe x u 4goten bout me?' scammers getti...\n",
       "3415    LIFE has never been this much fun and great un...\n",
       "4012    You will be receiving this week's Triple Echo ...\n",
       "3635    Customer service announcement. We recently tri...\n",
       "2067    Sexy Singles are waiting for you! Text your AG...\n",
       "2911    Sorry! U can not unsubscribe yet. THE MOB offe...\n",
       "4387    RECPT 1/3. You have ordered a Ringtone. Your o...\n",
       "867     What do U want for Xmas? How about 100 free te...\n",
       "1773                    Call FREEPHONE 0800 542 0578 now!\n",
       "1683    todays vodafone numbers ending with 0089(my la...\n",
       "3560    Auction round 4. The highest bid is now 짙54. N...\n",
       "2819    ROMCAPspam Everyone around should be respondin...\n",
       "729     Email AlertFrom: Jeri StewartSize: 2KBSubject:...\n",
       "4242    accordingly. I repeat, just text the word ok o...\n",
       "4236    Show ur colours! Euro 2004 2-4-1 Offer! Get an...\n",
       "1134    Dont forget you can place as many FREE Request...\n",
       "761     Urgent Ur 짙500 guaranteed award is still uncla...\n",
       "3844    Fantasy Football is back on your TV. Go to Sky...\n",
       "1271    network operator. The service is free. For T &...\n",
       "2360    Fantasy Football is back on your TV. Go to Sky...\n",
       "4291    thesmszone.com lets you send free anonymous an...\n",
       "4492    Latest Nokia Mobile or iPOD MP3 Player +짙400 p...\n",
       "1634    0A$NETWORKS allow companies to bill for SMS, s...\n",
       "4665    Customer service announcement. We recently tri...\n",
       "759     Romantic Paris. 2 nights, 2 flights from 짙79 B...\n",
       "1042    We know someone who you know that fancies you....\n",
       "4905    Goal! Arsenal 4 (Henry, 7 v Liverpool 2 Henry ...\n",
       "4065    TBS/PERSOLVO. been chasing us since Sept for짙3...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[Y_test > Y_pred_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 1., 0., 0.])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_prob = clf.predict_proba(X_test_dtm)[:,1]\n",
    "Y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9139084825465726"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(Y_test, Y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#나이브 베이즈를 이용한 감정분석\n",
    "import sys\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def usage():\n",
    "    print(\"Usage : \")\n",
    "    print(\"python %s <data_dir>\" % sys.argv[0])\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    if len(sys.argv) < 2:\n",
    "        usage()\n",
    "        sys.exit(1)\n",
    "        \n",
    "    data_dir = sys.argv[1]\n",
    "    classes = ['pos', 'neg']\n",
    "    \n",
    "    trian_data = []\n",
    "    train_labels = []\n",
    "    test_data = []\n",
    "    test_labels = []\n",
    "    for curr_class in classes:\n",
    "        dirname = os.path.join(data_dir, curr_class)\n",
    "        for fname in os.listdir(dirname):\n",
    "            with open(os.path.join(dirname, fname), 'r') as f:\n",
    "                content = f.read()\n",
    "                if fname.startswith('cv9'):\n",
    "                    test_data.append(content)\n",
    "                    test_labels.append(curr_class)\n",
    "                else:\n",
    "                    train_data.append(contetnt)\n",
    "                    train_labels.append(curr_class)\n",
    "    \n",
    "    \n",
    "    vectorizer = TfidfVectorizer(min_df = 5,\n",
    "                                 max_df = 0.8,\n",
    "                                 sublinear_tf = True,\n",
    "                                 use_idf = True)\n",
    "    train_vectors = vectorizer.fit_transform(train_data)\n",
    "    test_vectors = vectorizer.transform(test_data)\n",
    "    \n",
    "    clf = MultinomialNB()\n",
    "    t0 = time.time()\n",
    "    clf.fit(train_vectors, train_labels)\n",
    "    t1 = time.time()\n",
    "    prediction = clf.predict(test_vectors)\n",
    "    \n",
    "    t2 = time.time()\n",
    "    time_train = t1- t0\n",
    "    time_predict = t2 - t1\n",
    "    \n",
    "    # Print results in a nice table\n",
    "    print(\"Results for NaiveBayes (MultinomialNB) \")\n",
    "    print(\"Training time: %fs; Prediction time: %fs\" % (time_train, time_predict))\n",
    "    print(classification_report(test_labels, prediction))\n",
    "    print \"Reviews Prediction\"\n",
    "    print prediction[10] + \"----\"+test_data[10]\n",
    "\n",
    "    print \"\\nReviews Prediction\"\n",
    "    print prediction[100] + \"----\" + test_data[100]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM을 이용한 감정분석\n",
    "# Run this script with command line argument\n",
    "# python sentimentanalysis_SVM.py /home/jalaj/PycharmProjects/NLPython/NLPython/ch8/sentimentanalysis/data  /home/jalaj/PycharmProjects/NLPython/NLPython/ch8/sentimentanalysis/data\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def usage():\n",
    "    print(\"Usage:\")\n",
    "    print(\"python %s <data_dir>\" % sys.argv[0])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    if len(sys.argv) < 2:\n",
    "        usage()\n",
    "        sys.exit(1)\n",
    "\n",
    "    data_dir = sys.argv[1]\n",
    "    classes = ['pos', 'neg']\n",
    "\n",
    "    # Read the data\n",
    "    train_data = []\n",
    "    train_labels = []\n",
    "    test_data = []\n",
    "    test_labels = []\n",
    "    for curr_class in classes:\n",
    "        dirname = os.path.join(data_dir, curr_class)\n",
    "        for fname in os.listdir(dirname):\n",
    "            with open(os.path.join(dirname, fname), 'r') as f:\n",
    "                content = f.read()\n",
    "                if fname.startswith('cv9'):\n",
    "                    test_data.append(content)\n",
    "                    test_labels.append(curr_class)\n",
    "                else:\n",
    "                    train_data.append(content)\n",
    "                    train_labels.append(curr_class)\n",
    "\n",
    "    # Create feature vectors\n",
    "    vectorizer = TfidfVectorizer(min_df=5,\n",
    "                                 max_df = 0.8,\n",
    "                                 sublinear_tf=True,\n",
    "                                 use_idf=True)\n",
    "    train_vectors = vectorizer.fit_transform(train_data)\n",
    "    test_vectors = vectorizer.transform(test_data)\n",
    "\n",
    "    # Perform classification with SVM, kernel=rbf\n",
    "    classifier_rbf = svm.SVC()\n",
    "    t0 = time.time()\n",
    "    classifier_rbf.fit(train_vectors, train_labels)\n",
    "    t1 = time.time()\n",
    "    prediction_rbf = classifier_rbf.predict(test_vectors)\n",
    "    t2 = time.time()\n",
    "    time_rbf_train = t1-t0\n",
    "    time_rbf_predict = t2-t1\n",
    "\n",
    "    # Perform classification with SVM, kernel=linear\n",
    "    classifier_linear = svm.SVC(kernel='linear')\n",
    "    t0 = time.time()\n",
    "    classifier_linear.fit(train_vectors, train_labels)\n",
    "    t1 = time.time()\n",
    "    prediction_linear = classifier_linear.predict(test_vectors)\n",
    "    t2 = time.time()\n",
    "    time_linear_train = t1-t0\n",
    "    time_linear_predict = t2-t1\n",
    "\n",
    "    # Perform classification with SVM, kernel=linear\n",
    "    classifier_liblinear = svm.LinearSVC()\n",
    "    t0 = time.time()\n",
    "    classifier_liblinear.fit(train_vectors, train_labels)\n",
    "    t1 = time.time()\n",
    "    prediction_liblinear = classifier_liblinear.predict(test_vectors)\n",
    "    t2 = time.time()\n",
    "    time_liblinear_train = t1-t0\n",
    "    time_liblinear_predict = t2-t1\n",
    "\n",
    "    # Print results in a nice table\n",
    "    print(\"Results for SVC(kernel=rbf)\")\n",
    "    print(\"Training time: %fs; Prediction time: %fs\" % (time_rbf_train, time_rbf_predict))\n",
    "    print(classification_report(test_labels, prediction_rbf))\n",
    "    print(\"Results for SVC(kernel=linear)\")\n",
    "    print(\"Training time: %fs; Prediction time: %fs\" % (time_linear_train, time_linear_predict))\n",
    "    print(classification_report(test_labels, prediction_linear))\n",
    "    print(\"Results for LinearSVC()\")\n",
    "    print(\"Training time: %fs; Prediction time: %fs\" % (time_liblinear_train, time_liblinear_predict))\n",
    "    print(classification_report(test_labels, prediction_liblinear))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#K-means-clustering을 이용한 문서분류 애플리케이션\n",
    "from IPython.display import Image\n",
    "Image(filename = 'C:/Users/admin/Desktop/새홀리기/kmeanexample.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import os\n",
    "import codecs\n",
    "from sklearn import feature_extraction\n",
    "import mpld3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100titles\n",
      "100links\n",
      "100synopses\n",
      "100genres\n"
     ]
    }
   ],
   "source": [
    "#데이터(import three lists: titles, links and wikipedia synopses)\n",
    "titles = open('C:/Users/admin/Desktop/새홀리기/title_list.txt').read().split('\\n')\n",
    "titles = titles[:100]\n",
    "links = open('C:/Users/admin/Desktop/새홀리기/link_list_imdb.txt').read().split('\\n')\n",
    "links = links[:100]\n",
    "synopses_wiki = open('C:/Users/admin/Desktop/새홀리기/synopses_list_wiki.txt','rt',encoding = 'UTF8').read().split('\\n BREAKS HERE')\n",
    "synopses_wiki = synopses_wiki[:100]\n",
    "\n",
    "synopses_clean_wiki = []\n",
    "for text in synopses_wiki:\n",
    "    text = BeautifulSoup(text, 'html.parser').getText()\n",
    "    synopses_clean_wiki.append(text) #html형식을 unicide로 바꿔줌\n",
    "    \n",
    "synopses_wiki = synopses_clean_wiki\n",
    "\n",
    "genres = open('C:/Users/admin/Desktop/새홀리기/genres_list.txt').read().split('\\n')\n",
    "genres = genres[:100]\n",
    "\n",
    "print(str(len(titles)) + 'titles')\n",
    "print(str(len(links)) + 'links')\n",
    "print(str(len(synopses_wiki)) + 'synopses')\n",
    "print(str(len(genres)) + 'genres')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "synopses_imdb = open('C:/Users/admin/Desktop/새홀리기/synopses_list_imdb.txt').read().split('\\n BREAKS HERE')\n",
    "synopses_imdb = synopses_imdb[:100]\n",
    "\n",
    "synopses_clean_imdb = []\n",
    "\n",
    "for text in synopses_imdb:\n",
    "    text = BeautifulSoup(text, 'html.parser').getText()\n",
    "    synopses_clean_imdb.append(text)\n",
    "    \n",
    "synopses_imdb = synopses_clean_imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "synopses = []\n",
    "\n",
    "for i in range(len(synopses_wiki)):\n",
    "    item = synopses_wiki[i] + synopses_imdb[i]\n",
    "    synopses.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#제목에 인덱스 생성\n",
    "ranks = []\n",
    "for i in range(0, len(titles)):\n",
    "    ranks.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk에서 불용어 제거 \n",
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#단어의 어간을 출력하는 tokenizer와 stemmer\n",
    "def tokenize_and_stem(text):\n",
    "    #문장을 한번 tokenize하고 그 문장을 다시 tokenize(.을 잡아 낼 수 있다.)\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    \n",
    "    filtered_tokens = []\n",
    "    #알파벳만 출력으로 남김\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "            \n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems\n",
    "\n",
    "def tokenize_only(text):\n",
    "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    return filtered_tokens   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalvocab_stemmed = []\n",
    "totalvocab_tokenized = []\n",
    "for i in synopses:\n",
    "    allwords_stemmed = tokenize_and_stem(i)\n",
    "    totalvocab_stemmed.extend(allwords_stemmed) #extend는 list를 요소로 붙여준다.\n",
    "    \n",
    "    allwords_tokenized = tokenize_only(i)\n",
    "    totalvocab_tokenized.extend(allwords_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_frame = pd.DataFrame({'words' : totalvocab_tokenized}, index = totalvocab_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 19.3 s\n",
      "(100, 563)\n"
     ]
    }
   ],
   "source": [
    "#input vectorization\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df = 0.8, max_features = 200000,\n",
    "                                   min_df = 0.2, stop_words = 'english',\n",
    "                                   use_idf = True, tokenizer = tokenize_and_stem, ngram_range = (1,3))\n",
    "\n",
    "%time tfidf_matrix = tfidf_vectorizer.fit_transform(synopses) #synopses를 벡터화\n",
    "\n",
    "print(tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature 확인\n",
    "terms = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "dist = 1 - cosine_similarity(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.08 s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "num_clusters = 5\n",
    "\n",
    "km = KMeans(n_clusters = num_clusters)\n",
    "\n",
    "%time km.fit(tfidf_matrix)\n",
    "\n",
    "clusters = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:311: UserWarning: Trying to unpickle estimator KMeans from version pre-0.18 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: The file 'C:/Users/admin/Desktop/새홀리기/doc_cluster.pkl' has been generated with a joblib version less than 0.10. Please regenerate this pickle file.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "km = joblib.load('C:/Users/admin/Desktop/새홀리기/doc_cluster.pkl')\n",
    "cluster = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "films = {'title' : titles, 'rank' : ranks, 'synopsis' : synopses, 'cluster' : clusters, 'genre' : genres}\n",
    "frame = pd.DataFrame(films, index = [clusters], columns = ['rank', 'title', 'cluster', 'genre'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    32\n",
       "3    30\n",
       "2    26\n",
       "1     8\n",
       "0     4\n",
       "Name: cluster, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cluster\n",
       "0    72.2500\n",
       "1    54.1250\n",
       "2    58.0000\n",
       "3    39.8000\n",
       "4    47.6875\n",
       "Name: rank, dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = frame['rank'].groupby(frame['cluster'])\n",
    "grouped.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster : \n",
      "\n",
      "Cluster 0 words :  b'perform', b'music', b'ii', b'family', b'singing', b'join',\n",
      "\n",
      "Cluster 0 titles :  Amadeus, Giant, Nashville, Yankee Doodle Dandy,\n",
      "\n",
      "Cluster 1 words :  b'town', b'killed'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", b'little', b'men', b'gun', b\"n't\",\n",
      "\n",
      "Cluster 1 titles :  Saving Private Ryan, Unforgiven, To Kill a Mockingbird, Butch Cassidy and the Sundance Kid, The Treasure of the Sierra Madre, High Noon, The Grapes of Wrath, Shane,\n",
      "\n",
      "Cluster 2 words :  b'car', b'police', b'killed', b'father', b'murders', b'driving',\n",
      "\n",
      "Cluster 2 titles :  The Godfather, Casablanca, The Godfather: Part II, Psycho, Sunset Blvd., Vertigo, West Side Story, The Silence of the Lambs, Chinatown, The Good, the Bad and the Ugly, Goodfellas, The French Connection, It Happened One Night, Rain Man, Fargo, Network, American Graffiti, Pulp Fiction, The Maltese Falcon, A Clockwork Orange, Taxi Driver, Double Indemnity, Rebel Without a Cause, Rear Window, The Third Man, North by Northwest,\n",
      "\n",
      "Cluster 3 words :  b'army', b'soldiers', b'killed', b'war', b'captain', b'command',\n",
      "\n",
      "Cluster 3 titles :  The Shawshank Redemption, Schindler's List, One Flew Over the Cuckoo's Nest, The Wizard of Oz, Titanic, Lawrence of Arabia, The Sound of Music, Star Wars, 2001: A Space Odyssey, The Bridge on the River Kwai, Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb, Apocalypse Now, The Lord of the Rings: The Return of the King, Gladiator, From Here to Eternity, Raiders of the Lost Ark, Ben-Hur, Doctor Zhivago, Patton, Jaws, Braveheart, Platoon, Dances with Wolves, The Pianist, The Deer Hunter, All Quiet on the Western Front, Close Encounters of the Third Kind, The African Queen, Stagecoach, Mutiny on the Bounty,\n",
      "\n",
      "Cluster 4 words :  b'george', b'love', b'friends', b'home', b'marries', b'film',\n",
      "\n",
      "Cluster 4 titles :  Raging Bull, Gone with the Wind, Citizen Kane, On the Waterfront, Forrest Gump, E.T. the Extra-Terrestrial, Singin' in the Rain, It's a Wonderful Life, Some Like It Hot, 12 Angry Men, Gandhi, Rocky, A Streetcar Named Desire, The Philadelphia Story, An American in Paris, The Best Years of Our Lives, My Fair Lady, The Apartment, The Exorcist, City Lights, The King's Speech, A Place in the Sun, Midnight Cowboy, Mr. Smith Goes to Washington, Annie Hall, Out of Africa, Good Will Hunting, Terms of Endearment, Tootsie, The Green Mile, The Graduate, Wuthering Heights,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "print(\"Top terms per cluster : \")\n",
    "print()\n",
    "order_centroids = km.cluster_centers_.argsort()[:,::-1]\n",
    "for i in range(num_clusters):\n",
    "    print(\"Cluster %d words : \" % i, end = '')\n",
    "    for ind in order_centroids[i, :6]:\n",
    "        print(' %s' % vocab_frame.ix[terms[ind].split(' ')].values.tolist()[0][0].encode('utf-8', 'ignore' ), end=',')\n",
    "    print()\n",
    "    print()\n",
    "    print(\"Cluster %d titles : \" % i, end = '')\n",
    "    for title in frame.loc[i]['title'].values.tolist():\n",
    "        print(' %s,' % title, end = '')\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is purely to help export tables to html and to correct for my 0 start rank (so that Godfather is 1, not 0)\n",
    "frame['Rank'] = frame['rank'] + 1\n",
    "frame['Title'] = frame['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table border=\"1\" class=\"dataframe\">\n",
      "  <thead>\n",
      "    <tr style=\"text-align: right;\">\n",
      "      <th>Rank</th>\n",
      "      <th>Title</th>\n",
      "    </tr>\n",
      "  </thead>\n",
      "  <tbody>\n",
      "    <tr>\n",
      "      <td>37</td>\n",
      "      <td>Saving Private Ryan</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>38</td>\n",
      "      <td>Unforgiven</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>43</td>\n",
      "      <td>To Kill a Mockingbird</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>53</td>\n",
      "      <td>Butch Cassidy and the Sundance Kid</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>54</td>\n",
      "      <td>The Treasure of the Sierra Madre</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>57</td>\n",
      "      <td>High Noon</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>79</td>\n",
      "      <td>The Grapes of Wrath</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>80</td>\n",
      "      <td>Shane</td>\n",
      "    </tr>\n",
      "  </tbody>\n",
      "</table>\n"
     ]
    }
   ],
   "source": [
    "#export tables to HTML\n",
    "print(frame[['Rank', 'Title']].loc[frame['cluster'] == 1].to_html(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

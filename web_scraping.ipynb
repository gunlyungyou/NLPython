{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simplify data science \n",
      "SDS\n",
      "I’m data science researcher by practice and data scientist by profession. I like to deal with data science related problems. My research interest lies into Big Data Analytics , Natural Language Processing , Machine Learning and Deep Learning.\n",
      "I am still learning myself, but I found that writing posts and tutorials is the best way to deepen my own understanding and knowledge. On this platform, I’m sharing my experiences and also coming up with tutorials for beginners and posting articles. I am happy to help in any way I can. So don’t hesitate to get in touch!\n"
     ]
    }
   ],
   "source": [
    "#beautifulsoup를 이용한 web scraping\n",
    "import requests \n",
    "from bs4 import BeautifulSoup \n",
    "  \n",
    " \n",
    "  \n",
    " \n",
    "def Get_the_page_by_beautibulsoup(): \n",
    "    page = requests.get(\"https://simplifydatascience.wordpress.com/about/\") \n",
    "    #print page.status_code \n",
    "    #print page.content \n",
    "    soup = BeautifulSoup(page.content, 'html.parser') \n",
    "    #print soup() \n",
    "    #print(soup.prettify()) #display source of the html page in readable format. \n",
    "    soup = BeautifulSoup(page.content, 'html.parser') \n",
    "    print(soup.find_all('p')[0].get_text()) \n",
    "    print(soup.find_all('p')[1].get_text()) \n",
    "    print(soup.find_all('p')[2].get_text()) \n",
    "    print(soup.find_all('p')[3].get_text())\n",
    "  \n",
    " \n",
    "  \n",
    " \n",
    "if __name__ ==\"__main__\": \n",
    "     Get_the_page_by_beautibulsoup() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapy를 이용한 web scraping\n",
    "$ conda install -c conda-forge scrapy\n",
    "$ scrapy startproject web_scraping_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "\n",
    "class WebScrapingTestItem(scrapy.Item):\n",
    "    title = scrapy.Field()\n",
    "    url = scrapy.Field()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stackoverflow의 한 페이지를 scrapy\n",
    "from scrapy import Spider\n",
    "from scrapy.selector import Selector\n",
    "\n",
    "class WebScrapingTestspider(Spider):\n",
    "    name = \"WebScrapingTestspider\"\n",
    "    allowed_domains = [\"stackoverflow.com\"]\n",
    "    start_urls = [\n",
    "        \"http://stackoverflow.com/questions?pagesize=50&sort=newest\",\n",
    "    ]\n",
    "    \n",
    "    def parse(self, response):\n",
    "        questions = Selector(response).xpath('//div[@class=\"summary\"]/h3')\n",
    "        \n",
    "        for question in questions:\n",
    "            item = dict()\n",
    "            item['title'] = question.xpath(\n",
    "                'a[@class=\"question-hyperlink\"]/text()').extract()[0]\n",
    "            item['url'] = question.xpath(\n",
    "                'a[@class=\"question-hyperlink\"]/@href').extract()[0]\n",
    "            yield item\n",
    "            \n",
    "\n",
    "#Now you can run this by using following commands. \n",
    "#$ cd web_scraping_test/web_scraping_test \n",
    "#If you wnat to export data in csv format execute the following command \n",
    "#$ scrapy crawl WebScrapingTestspider -o result.csv -t csv \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
